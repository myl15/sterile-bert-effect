# === Paths ===
data_dir: "data"
ud_dir: "data/ud"
output_dir: "outputs"

# === Wikipedia Download ===
wiki:
  en_config: "20220301.en"
  fr_config: "20220301.fr"
  max_articles_en: 50000
  max_articles_fr: 50000
  min_article_length: 200

# === Sterilization ===
sterilize:
  remove_digits: true
  remove_urls: true
  remove_shared_punct: true

# === Tokenizer ===
tokenizer:
  vocab_size: 30000
  min_frequency: 3
  special_tokens: ["[PAD]", "[UNK]", "[CLS]", "[SEP]", "[MASK]"]

# === Model ===
model:
  num_hidden_layers: 4
  hidden_size: 256
  num_attention_heads: 4
  intermediate_size: 1024
  max_position_embeddings: 128

# === MLM Pre-training ===
pretrain:
  epochs: 3
  batch_size: 256
  learning_rate: 3.0e-5
  warmup_ratio: 0.1
  weight_decay: 0.01
  mlm_probability: 0.15
  max_seq_length: 128
  bf16: true
  gradient_accumulation_steps: 1
  save_steps: 5000
  logging_steps: 500
  seed: 42

# === POS Fine-tuning ===
finetune:
  epochs: 10
  batch_size: 64
  learning_rate: 5.0e-5
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_seq_length: 128
  seed: 42
  en_treebank: "en_ewt"
  fr_treebank: "fr_gsd"
